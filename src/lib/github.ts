export type Repo = {
  id: number;
  name: string;
  full_name: string;
  html_url: string;
  private: boolean;
};

const BASE = 'https://api.github.com';

// é€šç”¨çš„Tokenè¯»å–å‡½æ•°
export function getGitHubToken(): string | null {
  // ä¼˜å…ˆä»localStorageè¯»å–
  if (typeof window !== 'undefined') {
    const token = localStorage.getItem('gh_token');
    if (token) return token;
    
    // å¤‡ç”¨ï¼šä»cookieè¯»å–
    const cookies = document.cookie.split(';');
    for (const cookie of cookies) {
      const [name, value] = cookie.trim().split('=');
      if (name === 'gh_token') {
        return decodeURIComponent(value);
      }
    }
  }
  return null;
}

// éªŒè¯GitHub Tokenæ˜¯å¦æœ‰æ•ˆ
export async function validateGitHubToken(token: string): Promise<boolean> {
  try {
    const response = await fetch('https://api.github.com/user', {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });
    
    return response.ok;
  } catch (error) {
    console.error('Token validation failed:', error);
    return false;
  }
}

// éªŒè¯å½“å‰å­˜å‚¨çš„tokenæ˜¯å¦æœ‰æ•ˆ
export async function validateCurrentToken(): Promise<boolean> {
  const token = getGitHubToken();
  if (!token) return false;
  
  return await validateGitHubToken(token);
}

// æ¸…ç†æ‰€æœ‰tokenç›¸å…³çš„å­˜å‚¨
export function clearGitHubToken(): void {
  if (typeof window !== 'undefined') {
    // æ¸…é™¤localStorage
    localStorage.removeItem('gh_token');
    localStorage.removeItem('github_token'); // å…¼å®¹æ—§ç‰ˆæœ¬
    
    // æ¸…é™¤æ‰€æœ‰ç›¸å…³çš„cookie
    const cookiesToClear = ['gh_token', 'github_token'];
    cookiesToClear.forEach(cookieName => {
      document.cookie = `${cookieName}=; Path=/; Expires=Thu, 01 Jan 1970 00:00:00 GMT; SameSite=Lax`;
      document.cookie = `${cookieName}=; Path=/; Domain=${window.location.hostname}; Expires=Thu, 01 Jan 1970 00:00:00 GMT; SameSite=Lax`;
    });
    
    // æ¸…é™¤sessionStorageä¸­çš„ç›¸å…³æ•°æ®
    sessionStorage.removeItem('newAlbumForm');
    sessionStorage.removeItem('uploadedFiles');
    
    // æ¸…é™¤å…¶ä»–å¯èƒ½çš„ç¼“å­˜
    try {
      if ('caches' in window) {
        caches.keys().then(names => {
          names.forEach(name => {
            caches.delete(name);
          });
        });
      }
    } catch (error) {
      console.warn('Failed to clear caches:', error);
    }
  }
}

// å®Œæ•´çš„logoutå‡½æ•°
export function logout(): void {
  clearGitHubToken();
  
  // è·³è½¬åˆ°ç™»å½•é¡µé¢
  if (typeof window !== 'undefined') {
    window.location.href = '/login';
  }
}

// URLç¼–ç å·¥å…·å‡½æ•°ï¼Œæ­£ç¡®å¤„ç†ä¸­æ–‡å­—ç¬¦
export function encodeGitHubPath(path: string): string {
  // å¯¹è·¯å¾„ä¸­çš„æ¯ä¸ªéƒ¨åˆ†è¿›è¡Œç¼–ç ï¼Œä½†ä¿ç•™æ–œæ 
  return path.split('/').map(part => encodeURIComponent(part)).join('/');
}

// URLè§£ç å·¥å…·å‡½æ•°
export function decodeGitHubPath(path: string): string {
  try {
    return decodeURIComponent(path);
  } catch (error) {
    console.warn('Failed to decode path:', path, error);
    return path;
  }
}

// è·å–ä»“åº“çš„é»˜è®¤åˆ†æ”¯
export async function getDefaultBranch(token: string, owner: string, repo: string): Promise<string> {
  try {
    const response = await fetch(`${BASE}/repos/${owner}/${repo}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });
    
    if (!response.ok) {
      throw new Error(`Failed to get repository info: ${response.statusText}`);
    }
    
    const repoData = await response.json();
    return repoData.default_branch || 'main';
  } catch (error) {
    console.warn('Failed to get default branch, falling back to main:', error);
    return 'main'; // é»˜è®¤ä½¿ç”¨ main åˆ†æ”¯
  }
}

export async function listRepos(token: string): Promise<Repo[]> {
  // Include both public and private repos the user can access
  const params = new URLSearchParams({
    per_page: '100',
    visibility: 'all',
    affiliation: 'owner,collaborator,organization_member',
    sort: 'updated'
  });
  const res = await fetch(`${BASE}/user/repos?${params.toString()}`, {
    headers: {
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    }
  });
  if (!res.ok) throw new Error(`Failed to load repos: ${res.status}`);
  return (await res.json()) as Repo[];
}

export async function createRepo(token: string, name: string, isPrivate = false): Promise<Repo> {
  const res = await fetch(`${BASE}/user/repos`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    },
    body: JSON.stringify({ name, private: isPrivate })
  });
  
  if (!res.ok) {
    const errorData = await res.json().catch(() => ({}));
    
    switch (res.status) {
      case 409:
        throw new Error(`ä»“åº“åç§° "${name}" å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°`);
      case 422:
        throw new Error(`ä»“åº“åç§° "${name}" æ— æ•ˆï¼Œè¯·ä½¿ç”¨æœ‰æ•ˆçš„ä»“åº“åç§°`);
      case 401:
        throw new Error('GitHub tokenæ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•');
      case 403:
        throw new Error('æ²¡æœ‰æƒé™åˆ›å»ºä»“åº“ï¼Œè¯·æ£€æŸ¥tokenæƒé™');
      default:
        throw new Error(`åˆ›å»ºä»“åº“å¤±è´¥: ${errorData.message || res.statusText} (${res.status})`);
    }
  }
  
  return (await res.json()) as Repo;
}

export interface UploadFileOptions {
  owner: string;
  repo: string;
  path: string;
  content: string; // base64 encoded content
  message: string;
  branch?: string;
}

export async function uploadFile(token: string, options: UploadFileOptions): Promise<any> {
  const { owner, repo, path, content, message } = options;
  
  // åŠ¨æ€è·å–é»˜è®¤åˆ†æ”¯
  const branch = options.branch || await getDefaultBranch(token, owner, repo);
  
  // First, try to get the existing file to get its SHA (for updates)
  let sha: string | undefined;
  try {
    const existingRes = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${path}?ref=${branch}`, {
      headers: {
        Accept: 'application/vnd.github+json',
        Authorization: `token ${token}`
      }
    });
    if (existingRes.ok) {
      const existingFile = await existingRes.json();
      sha = existingFile.sha;
    }
  } catch (error) {
    // File doesn't exist, which is fine for new uploads
  }

  // Upload or update the file
  const body: any = {
    message,
    content,
    branch
  };
  
  if (sha) {
    body.sha = sha; // Required for updates
  }

  const res = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${path}`, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    },
    body: JSON.stringify(body)
  });

  if (!res.ok) {
    const errorText = await res.text();
    throw new Error(`Failed to upload file: ${res.status} - ${errorText}`);
  }
  
  return await res.json();
}

// Helper function to convert File to base64
export function fileToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const result = reader.result as string;
      // Remove the data URL prefix (e.g., "data:image/jpeg;base64,")
      const base64 = result.split(',')[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

// Get repository contents (directories)
export async function getRepoContents(token: string, owner: string, repo: string, path: string = ''): Promise<any[]> {
  const res = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${path}`, {
    headers: {
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    }
  });
  
  if (!res.ok) {
    if (res.status === 404) {
      return []; // Repository or path doesn't exist
    }
    throw new Error(`Failed to get repo contents: ${res.status}`);
  }
  
  return await res.json();
}

// Get existing album directories
export async function getExistingAlbumUrls(token: string, owner: string, repo: string): Promise<string[]> {
  const contents = await getRepoContents(token, owner, repo);
  return contents
    .filter(item => item.type === 'dir')
    .map(item => item.name);
}

// é€šç”¨çš„GitHubæ–‡ä»¶è¯»å–å‡½æ•°
export async function fetchGitHubFile(token: string, owner: string, repo: string, path: string): Promise<string> {
  const response = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${path}`, {
    headers: {
      'Authorization': `token ${token}`,
      'Accept': 'application/vnd.github+json'
    }
  });
  
  if (!response.ok) {
    throw new Error(`Failed to fetch ${path}: ${response.statusText}`);
  }
  
  const data = await response.json();
  // ä½¿ç”¨ TextDecoder æ­£ç¡®å¤„ç† UTF-8 ç¼–ç 
  const binaryString = atob(data.content);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return new TextDecoder('utf-8').decode(bytes);
}

// é€šç”¨çš„GitHubæ–‡ä»¶å†™å…¥å‡½æ•°
export async function updateGitHubFile(
  token: string, 
  owner: string, 
  repo: string, 
  path: string, 
  content: string, 
  message: string,
  sha?: string,
  branch?: string
): Promise<any> {
  // åŠ¨æ€è·å–é»˜è®¤åˆ†æ”¯
  const targetBranch = branch || await getDefaultBranch(token, owner, repo);
  const body: any = {
    message,
    content: btoa(unescape(encodeURIComponent(content))), // æ­£ç¡®å¤„ç†UTF-8ç¼–ç 
    branch: targetBranch
  };

  if (sha) {
    body.sha = sha;
  }

  const response = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${path}`, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
      'Accept': 'application/vnd.github+json',
      'Authorization': `token ${token}`
    },
    body: JSON.stringify(body)
  });

  if (!response.ok) {
    const errorData = await response.text();
    throw new Error(`GitHub APIé”™è¯¯ (${response.status}): ${errorData}`);
  }

  return await response.json();
}

// è·å–æ–‡ä»¶SHAçš„å‡½æ•°
export async function getFileSha(token: string, owner: string, repo: string, path: string): Promise<string | undefined> {
  try {
    const response = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${path}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });
    
    if (response.ok) {
      const data = await response.json();
      return data.sha;
    }
    return undefined;
  } catch (error) {
    return undefined;
  }
}

// Batch upload multiple files in a single commit
export interface BatchUploadFile {
  path: string;
  content: string; // base64 encoded
}

// åˆå§‹åŒ–ç©ºä»“åº“çš„å‡½æ•°
// æ–°çš„æ‰¹é‡æäº¤å‡½æ•°ï¼Œç”¨äºç©ºä»“åº“åˆå§‹åŒ–
export async function initializeEmptyRepoWithBatch(
  token: string,
  owner: string,
  repo: string,
  files: BatchUploadFile[],
  message: string,
  branch: string = 'main'
): Promise<any> {
  try {
    // å¯¹äºç©ºä»“åº“ï¼Œå…ˆåˆ›å»ºä¸€ä¸ªåˆå§‹æ–‡ä»¶æ¥åˆå§‹åŒ–Gitå¯¹è±¡å­˜å‚¨
    const firstFile = files[0];
    if (!firstFile) {
      throw new Error('No files to upload');
    }

    // å…ˆæ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    const checkResponse = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${firstFile.path}`, {
      headers: {
        Accept: 'application/vnd.github+json',
        Authorization: `token ${token}`
      }
    });

    let requestBody: any = {
      message: `Initialize repository with ${firstFile.path}`,
      content: firstFile.content,
      branch: branch
    };

    // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œéœ€è¦æä¾› sha æ¥æ›´æ–°
    if (checkResponse.ok) {
      const existingFile = await checkResponse.json();
      requestBody.sha = existingFile.sha;
      requestBody.message = `Update ${firstFile.path}`;
      console.log(`ğŸ“ Updating existing file: ${firstFile.path}`);
    } else {
      console.log(`ğŸ“„ Creating new file: ${firstFile.path}`);
    }

    // ä½¿ç”¨Contents APIåˆ›å»ºæˆ–æ›´æ–°ç¬¬ä¸€ä¸ªæ–‡ä»¶æ¥åˆå§‹åŒ–ä»“åº“
    const initRes = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${firstFile.path}`, {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        Accept: 'application/vnd.github+json',
        Authorization: `token ${token}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!initRes.ok) {
      const errorData = await initRes.json().catch(() => ({}));
      throw new Error(`Failed to initialize repo: ${initRes.status} - ${errorData.message || initRes.statusText}`);
    }

    console.log(`âœ… Repository initialized with ${firstFile.path}`);

    // å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if (files.length === 1) {
      return await initRes.json();
    }

    // ç­‰å¾…ä¸€ä¸‹è®©ä»“åº“å®Œå…¨åˆå§‹åŒ–
    await new Promise(resolve => setTimeout(resolve, 1000));

    // å¯¹äºå‰©ä½™çš„æ–‡ä»¶ï¼Œä½¿ç”¨æ‰¹é‡ä¸Šä¼ 
    const remainingFiles = files.slice(1);
    return await batchUploadFiles(token, owner, repo, remainingFiles, message, branch);

  } catch (error) {
    console.error('Failed to initialize empty repo with batch:', error);
    throw error;
  }
}

export async function initializeEmptyRepo(
  token: string,
  owner: string,
  repo: string,
  files: BatchUploadFile[],
  message: string,
  branch: string = 'main'
): Promise<any> {
  // åˆ†ç¦»æ ¹ç›®å½•æ–‡ä»¶å’ŒåµŒå¥—ç›®å½•æ–‡ä»¶
  const rootFiles = files.filter(file => !file.path.includes('/'));
  const nestedFiles = files.filter(file => file.path.includes('/'));
  
  // å…ˆåˆ›å»ºæ ¹ç›®å½•æ–‡ä»¶æ¥åˆå§‹åŒ–ä»“åº“
  for (const file of rootFiles) {
    try {
      // éªŒè¯base64ç¼–ç 
      try {
        atob(file.content);
      } catch (e) {
        console.error(`Invalid base64 content for ${file.path}:`, file.content.substring(0, 100));
        throw new Error(`Invalid base64 encoding for ${file.path}`);
      }
      
      // å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
      const checkResponse = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${file.path}`, {
        headers: {
          Accept: 'application/vnd.github+json',
          Authorization: `token ${token}`
        }
      });

      let requestBody: any = {
        message: `Add ${file.path}`,
        content: file.content,
        branch: branch
      };

      // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œéœ€è¦æä¾› sha æ¥æ›´æ–°
      if (checkResponse.ok) {
        const existingFile = await checkResponse.json();
        requestBody.sha = existingFile.sha;
        requestBody.message = `Update ${file.path}`;
        console.log(`ğŸ“ Updating existing file: ${file.path}`);
      } else {
        console.log(`ğŸ“„ Creating new file: ${file.path}`);
      }

      const response = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${file.path}`, {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
          Accept: 'application/vnd.github+json',
          Authorization: `token ${token}`
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        console.error(`âŒ ${file.path}: ${response.status} - ${errorData.message || response.statusText}`);
        throw new Error(`Failed to create ${file.path}: ${response.status} - ${errorData.message || response.statusText}`);
      }
      
      console.log(`Successfully created: ${file.path}`);
    } catch (error) {
      console.error(`Error creating ${file.path}:`, error);
      throw error;
    }
  }

  // ç­‰å¾…ä¸€ä¸‹è®©ä»“åº“å®Œå…¨åˆå§‹åŒ–
  if (rootFiles.length > 0) {
    await new Promise(resolve => setTimeout(resolve, 2000)); // å¢åŠ ç­‰å¾…æ—¶é—´
  }

  // ç„¶ååˆ›å»ºåµŒå¥—ç›®å½•æ–‡ä»¶
  for (const file of nestedFiles) {
    try {
      // éªŒè¯base64ç¼–ç 
      try {
        atob(file.content);
      } catch (e) {
        console.error(`Invalid base64 content for ${file.path}:`, file.content.substring(0, 100));
        throw new Error(`Invalid base64 encoding for ${file.path}`);
      }
      
      // ç­‰å¾…ä¸€ä¸‹ç¡®ä¿ç›®å½•æ–‡ä»¶å·²åˆ›å»º
      await new Promise(resolve => setTimeout(resolve, 500));
      
      // å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
      const checkResponse = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${file.path}`, {
        headers: {
          Accept: 'application/vnd.github+json',
          Authorization: `token ${token}`
        }
      });

      let requestBody: any = {
        message: `Add ${file.path}`,
        content: file.content,
        branch: branch
      };

      // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œéœ€è¦æä¾› sha æ¥æ›´æ–°
      if (checkResponse.ok) {
        const existingFile = await checkResponse.json();
        requestBody.sha = existingFile.sha;
        requestBody.message = `Update ${file.path}`;
        console.log(`ğŸ“ Updating existing file: ${file.path}`);
      } else {
        console.log(`ğŸ“„ Creating new file: ${file.path}`);
      }

      const response = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${file.path}`, {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
          Accept: 'application/vnd.github+json',
          Authorization: `token ${token}`
        },
        body: JSON.stringify(requestBody)
      });
      console.log(response);
      if (!response.ok) {
          const errorData = await response.json().catch(() => ({}));
          console.error(`âŒ ${file.path}: ${response.status} - ${errorData.message || response.statusText}`);
          throw new Error(`Failed to create ${file.path}: ${response.status} - ${errorData.message || response.statusText}`);
        }
      
      console.log(`Successfully created: ${file.path}`);
    } catch (error) {
      console.error(`Error creating ${file.path}:`, error);
      throw error;
    }
  }

  return { message: 'Repository initialized successfully' };
}

export async function batchUploadFiles(
  token: string, 
  owner: string, 
  repo: string, 
  files: BatchUploadFile[], 
  message: string,
  branch?: string
): Promise<any> {
  // åŠ¨æ€è·å–é»˜è®¤åˆ†æ”¯
  const targetBranch = branch || await getDefaultBranch(token, owner, repo);
  
  // Get the latest commit SHA
  const branchRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
    headers: {
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    }
  });
  
  let latestCommitSha: string | null = null;
  let baseTreeSha: string | null = null;
  
  if (branchRes.ok) {
    // ä»“åº“å·²æœ‰åˆ†æ”¯
    const branchData = await branchRes.json();
    latestCommitSha = branchData.object.sha;
    
    // Get the tree SHA from the latest commit
    const commitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits/${latestCommitSha}`, {
      headers: {
        Accept: 'application/vnd.github+json',
        Authorization: `token ${token}`
      }
    });
    
    if (!commitRes.ok) {
      throw new Error(`Failed to get commit info: ${commitRes.status}`);
    }
    
    const commitData = await commitRes.json();
    baseTreeSha = commitData.tree.sha;
  } else if (branchRes.status === 409 || branchRes.status === 404) {
    // æ–°ä»“åº“æˆ–ç©ºä»“åº“ï¼Œæ²¡æœ‰åˆ†æ”¯ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µ
    console.log('Empty repository, no existing branches');
  } else {
    throw new Error(`Failed to get branch info: ${branchRes.status}`);
  }

  
  // Create blobs for all files
  const blobPromises = files.map(async (file) => {
    const blobRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/blobs`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Accept: 'application/vnd.github+json',
        Authorization: `token ${token}`
      },
      body: JSON.stringify({
        content: file.content,
        encoding: 'base64'
      })
    });
    
    if (!blobRes.ok) {
      const errorData = await blobRes.json().catch(() => ({}));
      throw new Error(`Failed to create blob for ${file.path}: ${blobRes.status} - ${errorData.message || blobRes.statusText}`);
    }
    
    const blobData = await blobRes.json();
    return {
      path: file.path,
      mode: '100644',
      type: 'blob',
      sha: blobData.sha
    };
  });
  
  const treeItems = await Promise.all(blobPromises);
  
  // Create new tree
  const treeBody: any = {
    tree: treeItems
  };
  
  // åªæœ‰åœ¨æœ‰base treeæ—¶æ‰æ·»åŠ 
  if (baseTreeSha) {
    treeBody.base_tree = baseTreeSha;
  }
  
  const treeRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/trees`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    },
    body: JSON.stringify(treeBody)
  });
  
  if (!treeRes.ok) {
    throw new Error(`Failed to create tree: ${treeRes.status}`);
  }
  
  const treeData = await treeRes.json();
  
  // Create new commit
  const commitBody: any = {
    message,
    tree: treeData.sha
  };
  
  // åªæœ‰åœ¨æœ‰çˆ¶æäº¤æ—¶æ‰æ·»åŠ 
  if (latestCommitSha) {
    commitBody.parents = [latestCommitSha];
  }
  
  const newCommitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    },
    body: JSON.stringify(commitBody)
  });
  
  if (!newCommitRes.ok) {
    throw new Error(`Failed to create commit: ${newCommitRes.status}`);
  }
  
  const newCommitData = await newCommitRes.json();
  
  // Update branch reference
  const updateRefRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
    method: 'PATCH',
    headers: {
      'Content-Type': 'application/json',
      Accept: 'application/vnd.github+json',
      Authorization: `token ${token}`
    },
    body: JSON.stringify({
      sha: newCommitData.sha
    })
  });
  
  if (!updateRefRes.ok) {
    throw new Error(`Failed to update branch: ${updateRefRes.status}`);
  }
  
  return newCommitData;
}

// åˆ é™¤GitHubç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹
// æ£€æŸ¥GitHub tokençš„æƒé™
export async function checkTokenPermissions(token: string): Promise<{
  hasRepoAccess: boolean;
  hasWorkflowAccess: boolean;
  scopes: string[];
  error?: string;
}> {
  try {
    // æ£€æŸ¥tokençš„scopes
    const response = await fetch(`${BASE}/user`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!response.ok) {
      return {
        hasRepoAccess: false,
        hasWorkflowAccess: false,
        scopes: [],
        error: `TokenéªŒè¯å¤±è´¥: ${response.status}`
      };
    }

    // ä»å“åº”å¤´è·å–scopes
    const scopesHeader = response.headers.get('X-OAuth-Scopes') || '';
    const scopes = scopesHeader.split(',').map(s => s.trim()).filter(s => s);

    // æ£€æŸ¥å¿…è¦çš„æƒé™
    const hasRepoAccess = scopes.includes('repo') || scopes.includes('public_repo');
    
    // workflowæƒé™æ£€æŸ¥ï¼š
    // 1. å¦‚æœæœ‰ 'repo' æƒé™ï¼Œåˆ™è‡ªåŠ¨åŒ…å«workflowæƒé™
    // 2. å¦‚æœåªæœ‰ 'public_repo' æƒé™ï¼Œåˆ™éœ€è¦é¢å¤–çš„ 'workflow' æƒé™
    // 3. å¦‚æœæœ‰æ˜ç¡®çš„ 'workflow' æƒé™ä¹Ÿå¯ä»¥
    const hasWorkflowAccess = (scopes.includes('public_repo') && scopes.includes('workflow')) ||
                             scopes.includes('workflow');

    return {
      hasRepoAccess,
      hasWorkflowAccess,
      scopes,
    };
  } catch (error) {
    return {
      hasRepoAccess: false,
      hasWorkflowAccess: false,
      scopes: [],
      error: `æ£€æŸ¥æƒé™æ—¶å‡ºé”™: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
    };
  }
}

// æ£€æŸ¥ä»“åº“æ˜¯å¦é…ç½®äº†æŒ‡å®šçš„å¯†é’¥
export async function checkRepositorySecret(
  token: string,
  owner: string,
  repo: string,
  secretName: string
): Promise<boolean> {
  try {
    const response = await fetch(`${BASE}/repos/${owner}/${repo}/actions/secrets/${secretName}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });
    
    // å¦‚æœè¿”å›200ï¼Œè¯´æ˜å¯†é’¥å­˜åœ¨
    return response.status === 200;
  } catch (error) {
    console.warn('Failed to check repository secret:', error);
    return false;
  }
}

// è·å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64ï¼ˆæ”¯æŒæœ¬åœ°é™æ€æ–‡ä»¶å’Œç½‘ç»œæ–‡ä»¶ï¼‰
export async function fetchImageAsBase64(imageUrl: string): Promise<string> {
  try {
    // å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œè½¬æ¢ä¸ºå®Œæ•´URL
    const fullUrl = imageUrl.startsWith('/') ? 
      `${window.location.origin}${imageUrl}` : 
      imageUrl;
    
    const response = await fetch(fullUrl);
    if (!response.ok) {
      throw new Error(`Failed to fetch image: ${response.status}`);
    }
    
    const arrayBuffer = await response.arrayBuffer();
    const uint8Array = new Uint8Array(arrayBuffer);
    
    // å°†ArrayBufferè½¬æ¢ä¸ºbase64
    let binary = '';
    for (let i = 0; i < uint8Array.byteLength; i++) {
      binary += String.fromCharCode(uint8Array[i]);
    }
    
    return btoa(binary);
  } catch (error) {
    console.error('Failed to fetch image:', error);
    throw error;
  }
}

// è‡ªåŠ¨å¯¼å…¥ä»“åº“åˆ°é¡¹ç›®
export async function importRepoToProject(repo: Repo): Promise<boolean> {
  try {
    const GALLERIES_KEY = 'pictor_galleries';
    
    // è·å–ç°æœ‰çš„ç”»å»Šåˆ—è¡¨
    const existingGalleries = JSON.parse(localStorage.getItem(GALLERIES_KEY) || '[]');
    
    // æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
    const exists = existingGalleries.some((gallery: any) => gallery.full_name === repo.full_name);
    if (exists) {
      console.log('Repository already imported:', repo.full_name);
      return true;
    }
    
    // æ·»åŠ æ–°çš„ç”»å»Š
    const newGallery = {
      id: repo.id,
      full_name: repo.full_name,
      html_url: repo.html_url
    };
    
    const updatedGalleries = [...existingGalleries, newGallery];
    localStorage.setItem(GALLERIES_KEY, JSON.stringify(updatedGalleries));
    
    console.log('Successfully imported repository:', repo.full_name);
    return true;
  } catch (error) {
    console.error('Failed to import repository:', error);
    return false;
  }
}

export async function deleteDirectory(
  token: string,
  owner: string,
  repo: string,
  directoryPath: string,
  message: string,
  branch?: string
): Promise<any> {
  // åŠ¨æ€è·å–é»˜è®¤åˆ†æ”¯
  const targetBranch = branch || await getDefaultBranch(token, owner, repo);
  
  try {
    // 1. è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    const response = await fetch(`${BASE}/repos/${owner}/${repo}/contents/${encodeGitHubPath(directoryPath)}?ref=${targetBranch}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!response.ok) {
      if (response.status === 404) {
        throw new Error('ç›®å½•ä¸å­˜åœ¨');
      }
      throw new Error(`è·å–ç›®å½•å†…å®¹å¤±è´¥: ${response.statusText}`);
    }

    const files = await response.json();
    
    if (!Array.isArray(files)) {
      throw new Error('ç›®å½•è·¯å¾„æŒ‡å‘çš„ä¸æ˜¯ä¸€ä¸ªç›®å½•');
    }

    if (files.length === 0) {
      throw new Error('ç›®å½•ä¸ºç©ºï¼Œæ— éœ€åˆ é™¤');
    }

    // 2. è·å–å½“å‰åˆ†æ”¯çš„æœ€æ–°commit SHA
    const branchRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!branchRes.ok) {
      throw new Error(`è·å–åˆ†æ”¯ä¿¡æ¯å¤±è´¥: ${branchRes.statusText}`);
    }

    const branchData = await branchRes.json();
    const latestCommitSha = branchData.object.sha;

    // 3. è·å–å½“å‰commitçš„tree
    const commitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits/${latestCommitSha}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!commitRes.ok) {
      throw new Error(`è·å–commitä¿¡æ¯å¤±è´¥: ${commitRes.statusText}`);
    }

    const commitData = await commitRes.json();
    const baseTreeSha = commitData.tree.sha;

    // 4. è·å–å®Œæ•´çš„treeï¼Œæ’é™¤è¦åˆ é™¤çš„ç›®å½•
    const treeRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/trees/${baseTreeSha}?recursive=1`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!treeRes.ok) {
      throw new Error(`è·å–treeä¿¡æ¯å¤±è´¥: ${treeRes.statusText}`);
    }

    const treeData = await treeRes.json();
    
    // 5. è¿‡æ»¤æ‰è¦åˆ é™¤çš„ç›®å½•åŠå…¶æ‰€æœ‰å­æ–‡ä»¶
    const filteredTree = treeData.tree.filter((item: any) => {
      // ç¡®ä¿è·¯å¾„åŒ¹é…çš„å‡†ç¡®æ€§
      const itemPath = item.path;
      const targetPath = directoryPath;
      
      // å®Œå…¨åŒ¹é…ç›®å½•æœ¬èº«
      if (itemPath === targetPath) {
        console.log(`åˆ é™¤ç›®å½•: ${itemPath}`);
        return false;
      }
      
      // åŒ¹é…ç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å’Œå­ç›®å½•
      if (itemPath.startsWith(targetPath + '/')) {
        console.log(`åˆ é™¤å­æ–‡ä»¶: ${itemPath}`);
        return false;
      }
      
      return true;
    });
    
    console.log(`åŸå§‹æ–‡ä»¶æ•°: ${treeData.tree.length}, è¿‡æ»¤åæ–‡ä»¶æ•°: ${filteredTree.length}`);

    // 6. åˆ›å»ºæ–°çš„tree
    const newTreeRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/trees`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        tree: filteredTree.map((item: any) => ({
          path: item.path,
          mode: item.mode,
          type: item.type,
          sha: item.sha
        }))
      })
    });

    if (!newTreeRes.ok) {
      throw new Error(`åˆ›å»ºæ–°treeå¤±è´¥: ${newTreeRes.statusText}`);
    }

    const newTreeData = await newTreeRes.json();

    // 7. åˆ›å»ºæ–°çš„commit
    const newCommitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        message,
        tree: newTreeData.sha,
        parents: [latestCommitSha]
      })
    });

    if (!newCommitRes.ok) {
      throw new Error(`åˆ›å»ºcommitå¤±è´¥: ${newCommitRes.statusText}`);
    }

    const newCommitData = await newCommitRes.json();

    // 8. æ›´æ–°åˆ†æ”¯å¼•ç”¨
    const updateRefRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
      method: 'PATCH',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        sha: newCommitData.sha
      })
    });

    if (!updateRefRes.ok) {
      throw new Error(`æ›´æ–°åˆ†æ”¯å¤±è´¥: ${updateRefRes.statusText}`);
    }

    return newCommitData;
    
  } catch (error) {
    console.error('åˆ é™¤ç›®å½•å¤±è´¥:', error);
    throw error;
  }
}

export async function deleteFiles(
  token: string,
  owner: string,
  repo: string,
  filePaths: string[],
  message: string,
  branch?: string
): Promise<any> {
  const targetBranch = branch || await getDefaultBranch(token, owner, repo);

  const uniquePaths = Array.from(new Set(filePaths.map((p) => p.trim()).filter(Boolean)));
  if (uniquePaths.length === 0) {
    throw new Error('æ²¡æœ‰å¯åˆ é™¤çš„æ–‡ä»¶');
  }

  try {
    const branchRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!branchRes.ok) {
      throw new Error(`è·å–åˆ†æ”¯ä¿¡æ¯å¤±è´¥: ${branchRes.statusText}`);
    }

    const branchData = await branchRes.json();
    const latestCommitSha = branchData.object.sha;

    const commitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits/${latestCommitSha}`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!commitRes.ok) {
      throw new Error(`è·å–commitä¿¡æ¯å¤±è´¥: ${commitRes.statusText}`);
    }

    const commitData = await commitRes.json();
    const baseTreeSha = commitData.tree.sha;

    const treeRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/trees/${baseTreeSha}?recursive=1`, {
      headers: {
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      }
    });

    if (!treeRes.ok) {
      throw new Error(`è·å–treeä¿¡æ¯å¤±è´¥: ${treeRes.statusText}`);
    }

    const treeData = await treeRes.json();
    const deleteSet = new Set(uniquePaths);
    const filteredTree = treeData.tree.filter((item: any) => !deleteSet.has(item.path));

    if (filteredTree.length === treeData.tree.length) {
      throw new Error('æœªæ‰¾åˆ°è¦åˆ é™¤çš„æ–‡ä»¶');
    }

    const newTreeRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/trees`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        tree: filteredTree.map((item: any) => ({
          path: item.path,
          mode: item.mode,
          type: item.type,
          sha: item.sha
        }))
      })
    });

    if (!newTreeRes.ok) {
      throw new Error(`åˆ›å»ºæ–°treeå¤±è´¥: ${newTreeRes.statusText}`);
    }

    const newTreeData = await newTreeRes.json();

    const newCommitRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/commits`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        message,
        tree: newTreeData.sha,
        parents: [latestCommitSha]
      })
    });

    if (!newCommitRes.ok) {
      throw new Error(`åˆ›å»ºcommitå¤±è´¥: ${newCommitRes.statusText}`);
    }

    const newCommitData = await newCommitRes.json();

    const updateRefRes = await fetch(`${BASE}/repos/${owner}/${repo}/git/refs/heads/${targetBranch}`, {
      method: 'PATCH',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `token ${token}`,
        'Accept': 'application/vnd.github+json'
      },
      body: JSON.stringify({
        sha: newCommitData.sha
      })
    });

    if (!updateRefRes.ok) {
      throw new Error(`æ›´æ–°åˆ†æ”¯å¤±è´¥: ${updateRefRes.statusText}`);
    }

    return newCommitData;
  } catch (error) {
    console.error('åˆ é™¤æ–‡ä»¶å¤±è´¥:', error);
    throw error;
  }
}
